{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPsHSPNIusvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usfRt029u7fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twcr05ZsvATq",
        "colab_type": "text"
      },
      "source": [
        "If you are running on local directory you need to install cuda to run this Project. If you are running on colab and go to Notebook setting and use GPU as Hardware Accelrator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REniLjqzvA3Z",
        "colab_type": "code",
        "outputId": "adcb76c5-9ec4-4562-b67b-d14ecf7a8bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#downloading the dataset\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmmqvRuJvC0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_qFGxLvFIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZJb7YJFvG9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4i1uLIsvIjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WgNRBtMvKtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # creating cleaned input, output pairs\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ftbP7NgvMpW",
        "colab_type": "code",
        "outputId": "636592fc-20b3-4353-994d-d150b5a871e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#limiting no of examples\n",
        "num = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num)\n",
        "\n",
        "max_len_targ,max_len_inp = max_length(target_tensor),max_length(input_tensor)\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.232)\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23040 23040 6960 6960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WYgwwObvOb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating tensorflow dataset\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOoSH111vQZK",
        "colab_type": "code",
        "outputId": "6c30626f-ddf5-4d3d-bf1b-6fb7c7b13598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyOpfbVmvSQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating encoder and decoder attention model\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6QAgic_vT-r",
        "colab_type": "code",
        "outputId": "a9e7480c-0dc1-47f2-e0c3-0531325df8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXEO3N1MvVwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "    def call(self, query, values):\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02SZKlsAvXs_",
        "colab_type": "code",
        "outputId": "32956c41-7fb5-48ce-9c3f-c9a705190edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyFr33gmvZSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "    def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLxSneRYvb1O",
        "colab_type": "code",
        "outputId": "1a934680-eb70-45df-cef4-c23e56ac56bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJQ21z4yvdkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gV8ZziGvfZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vokxsvVEvg5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this tensor flow function is for running traning . This is called using sequent\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulTNUtBqvigW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8895c2f-8d9d-4ab2-d1d4-4336af9c3a29"
      },
      "source": [
        "# This bit of code does training in sequential order\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 10 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6264\n",
            "Epoch 1 Batch 10 Loss 2.8545\n",
            "Epoch 1 Batch 20 Loss 2.7843\n",
            "Epoch 1 Batch 30 Loss 2.5891\n",
            "Epoch 1 Batch 40 Loss 2.3983\n",
            "Epoch 1 Batch 50 Loss 2.4002\n",
            "Epoch 1 Batch 60 Loss 2.3752\n",
            "Epoch 1 Batch 70 Loss 2.2594\n",
            "Epoch 1 Batch 80 Loss 2.2392\n",
            "Epoch 1 Batch 90 Loss 2.1763\n",
            "Epoch 1 Batch 100 Loss 2.1268\n",
            "Epoch 1 Batch 110 Loss 2.1762\n",
            "Epoch 1 Batch 120 Loss 2.1323\n",
            "Epoch 1 Batch 130 Loss 2.1455\n",
            "Epoch 1 Batch 140 Loss 1.9619\n",
            "Epoch 1 Batch 150 Loss 2.0191\n",
            "Epoch 1 Batch 160 Loss 1.8815\n",
            "Epoch 1 Batch 170 Loss 1.9511\n",
            "Epoch 1 Batch 180 Loss 1.8761\n",
            "Epoch 1 Batch 190 Loss 1.8439\n",
            "Epoch 1 Batch 200 Loss 1.9084\n",
            "Epoch 1 Batch 210 Loss 1.8832\n",
            "Epoch 1 Batch 220 Loss 1.9119\n",
            "Epoch 1 Batch 230 Loss 1.8492\n",
            "Epoch 1 Batch 240 Loss 1.7785\n",
            "Epoch 1 Batch 250 Loss 1.8061\n",
            "Epoch 1 Batch 260 Loss 1.6859\n",
            "Epoch 1 Batch 270 Loss 1.7781\n",
            "Epoch 1 Batch 280 Loss 1.6655\n",
            "Epoch 1 Batch 290 Loss 1.6917\n",
            "Epoch 1 Batch 300 Loss 1.6340\n",
            "Epoch 1 Batch 310 Loss 1.7195\n",
            "Epoch 1 Batch 320 Loss 1.6644\n",
            "Epoch 1 Batch 330 Loss 1.6140\n",
            "Epoch 1 Batch 340 Loss 1.5899\n",
            "Epoch 1 Batch 350 Loss 1.5696\n",
            "Epoch 1 Loss 2.0452\n",
            "Time taken for 1 epoch 48.250447034835815 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.6360\n",
            "Epoch 2 Batch 10 Loss 1.5398\n",
            "Epoch 2 Batch 20 Loss 1.6475\n",
            "Epoch 2 Batch 30 Loss 1.6083\n",
            "Epoch 2 Batch 40 Loss 1.6839\n",
            "Epoch 2 Batch 50 Loss 1.5335\n",
            "Epoch 2 Batch 60 Loss 1.4574\n",
            "Epoch 2 Batch 70 Loss 1.6522\n",
            "Epoch 2 Batch 80 Loss 1.4746\n",
            "Epoch 2 Batch 90 Loss 1.4383\n",
            "Epoch 2 Batch 100 Loss 1.5247\n",
            "Epoch 2 Batch 110 Loss 1.5365\n",
            "Epoch 2 Batch 120 Loss 1.5723\n",
            "Epoch 2 Batch 130 Loss 1.4397\n",
            "Epoch 2 Batch 140 Loss 1.4216\n",
            "Epoch 2 Batch 150 Loss 1.3483\n",
            "Epoch 2 Batch 160 Loss 1.4020\n",
            "Epoch 2 Batch 170 Loss 1.4816\n",
            "Epoch 2 Batch 180 Loss 1.4729\n",
            "Epoch 2 Batch 190 Loss 1.3502\n",
            "Epoch 2 Batch 200 Loss 1.4306\n",
            "Epoch 2 Batch 210 Loss 1.4198\n",
            "Epoch 2 Batch 220 Loss 1.4101\n",
            "Epoch 2 Batch 230 Loss 1.2585\n",
            "Epoch 2 Batch 240 Loss 1.3360\n",
            "Epoch 2 Batch 250 Loss 1.4034\n",
            "Epoch 2 Batch 260 Loss 1.4862\n",
            "Epoch 2 Batch 270 Loss 1.4656\n",
            "Epoch 2 Batch 280 Loss 1.3462\n",
            "Epoch 2 Batch 290 Loss 1.2881\n",
            "Epoch 2 Batch 300 Loss 1.3031\n",
            "Epoch 2 Batch 310 Loss 1.2817\n",
            "Epoch 2 Batch 320 Loss 1.2540\n",
            "Epoch 2 Batch 330 Loss 1.2933\n",
            "Epoch 2 Batch 340 Loss 1.2324\n",
            "Epoch 2 Batch 350 Loss 1.2105\n",
            "Epoch 2 Loss 1.4173\n",
            "Time taken for 1 epoch 31.60170865058899 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0461\n",
            "Epoch 3 Batch 10 Loss 1.0819\n",
            "Epoch 3 Batch 20 Loss 1.1300\n",
            "Epoch 3 Batch 30 Loss 1.0852\n",
            "Epoch 3 Batch 40 Loss 1.0781\n",
            "Epoch 3 Batch 50 Loss 1.1146\n",
            "Epoch 3 Batch 60 Loss 1.1475\n",
            "Epoch 3 Batch 70 Loss 1.1701\n",
            "Epoch 3 Batch 80 Loss 1.0804\n",
            "Epoch 3 Batch 90 Loss 0.9925\n",
            "Epoch 3 Batch 100 Loss 1.1558\n",
            "Epoch 3 Batch 110 Loss 1.1037\n",
            "Epoch 3 Batch 120 Loss 0.9914\n",
            "Epoch 3 Batch 130 Loss 1.0511\n",
            "Epoch 3 Batch 140 Loss 0.9622\n",
            "Epoch 3 Batch 150 Loss 1.0216\n",
            "Epoch 3 Batch 160 Loss 1.0495\n",
            "Epoch 3 Batch 170 Loss 1.0596\n",
            "Epoch 3 Batch 180 Loss 1.0297\n",
            "Epoch 3 Batch 190 Loss 0.9782\n",
            "Epoch 3 Batch 200 Loss 1.0452\n",
            "Epoch 3 Batch 210 Loss 1.0491\n",
            "Epoch 3 Batch 220 Loss 0.8165\n",
            "Epoch 3 Batch 230 Loss 1.0055\n",
            "Epoch 3 Batch 240 Loss 0.9944\n",
            "Epoch 3 Batch 250 Loss 0.9293\n",
            "Epoch 3 Batch 260 Loss 0.9536\n",
            "Epoch 3 Batch 270 Loss 0.9124\n",
            "Epoch 3 Batch 280 Loss 0.9425\n",
            "Epoch 3 Batch 290 Loss 0.8671\n",
            "Epoch 3 Batch 300 Loss 0.8746\n",
            "Epoch 3 Batch 310 Loss 0.9926\n",
            "Epoch 3 Batch 320 Loss 0.9547\n",
            "Epoch 3 Batch 330 Loss 0.8460\n",
            "Epoch 3 Batch 340 Loss 0.8808\n",
            "Epoch 3 Batch 350 Loss 1.0792\n",
            "Epoch 3 Loss 1.0083\n",
            "Time taken for 1 epoch 31.64512276649475 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7405\n",
            "Epoch 4 Batch 10 Loss 0.6681\n",
            "Epoch 4 Batch 20 Loss 0.6725\n",
            "Epoch 4 Batch 30 Loss 0.6090\n",
            "Epoch 4 Batch 40 Loss 0.6732\n",
            "Epoch 4 Batch 50 Loss 0.6382\n",
            "Epoch 4 Batch 60 Loss 0.6231\n",
            "Epoch 4 Batch 70 Loss 0.7281\n",
            "Epoch 4 Batch 80 Loss 0.7259\n",
            "Epoch 4 Batch 90 Loss 0.6421\n",
            "Epoch 4 Batch 100 Loss 0.6673\n",
            "Epoch 4 Batch 110 Loss 0.6939\n",
            "Epoch 4 Batch 120 Loss 0.8617\n",
            "Epoch 4 Batch 130 Loss 0.7393\n",
            "Epoch 4 Batch 140 Loss 0.5318\n",
            "Epoch 4 Batch 150 Loss 0.6889\n",
            "Epoch 4 Batch 160 Loss 0.6861\n",
            "Epoch 4 Batch 170 Loss 0.6778\n",
            "Epoch 4 Batch 180 Loss 0.6596\n",
            "Epoch 4 Batch 190 Loss 0.7428\n",
            "Epoch 4 Batch 200 Loss 0.6669\n",
            "Epoch 4 Batch 210 Loss 0.6591\n",
            "Epoch 4 Batch 220 Loss 0.6211\n",
            "Epoch 4 Batch 230 Loss 0.7614\n",
            "Epoch 4 Batch 240 Loss 0.7458\n",
            "Epoch 4 Batch 250 Loss 0.7860\n",
            "Epoch 4 Batch 260 Loss 0.6652\n",
            "Epoch 4 Batch 270 Loss 0.7100\n",
            "Epoch 4 Batch 280 Loss 0.6231\n",
            "Epoch 4 Batch 290 Loss 0.7081\n",
            "Epoch 4 Batch 300 Loss 0.7212\n",
            "Epoch 4 Batch 310 Loss 0.6530\n",
            "Epoch 4 Batch 320 Loss 0.7079\n",
            "Epoch 4 Batch 330 Loss 0.6731\n",
            "Epoch 4 Batch 340 Loss 0.6305\n",
            "Epoch 4 Batch 350 Loss 0.6854\n",
            "Epoch 4 Loss 0.6798\n",
            "Time taken for 1 epoch 31.976282358169556 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4820\n",
            "Epoch 5 Batch 10 Loss 0.4658\n",
            "Epoch 5 Batch 20 Loss 0.3867\n",
            "Epoch 5 Batch 30 Loss 0.4759\n",
            "Epoch 5 Batch 40 Loss 0.4115\n",
            "Epoch 5 Batch 50 Loss 0.3686\n",
            "Epoch 5 Batch 60 Loss 0.3863\n",
            "Epoch 5 Batch 70 Loss 0.4440\n",
            "Epoch 5 Batch 80 Loss 0.5041\n",
            "Epoch 5 Batch 90 Loss 0.4362\n",
            "Epoch 5 Batch 100 Loss 0.4122\n",
            "Epoch 5 Batch 110 Loss 0.5079\n",
            "Epoch 5 Batch 120 Loss 0.3717\n",
            "Epoch 5 Batch 130 Loss 0.4699\n",
            "Epoch 5 Batch 140 Loss 0.3738\n",
            "Epoch 5 Batch 150 Loss 0.5636\n",
            "Epoch 5 Batch 160 Loss 0.5243\n",
            "Epoch 5 Batch 170 Loss 0.4345\n",
            "Epoch 5 Batch 180 Loss 0.4537\n",
            "Epoch 5 Batch 190 Loss 0.5091\n",
            "Epoch 5 Batch 200 Loss 0.4901\n",
            "Epoch 5 Batch 210 Loss 0.4719\n",
            "Epoch 5 Batch 220 Loss 0.5682\n",
            "Epoch 5 Batch 230 Loss 0.3884\n",
            "Epoch 5 Batch 240 Loss 0.4670\n",
            "Epoch 5 Batch 250 Loss 0.4100\n",
            "Epoch 5 Batch 260 Loss 0.4169\n",
            "Epoch 5 Batch 270 Loss 0.4056\n",
            "Epoch 5 Batch 280 Loss 0.4247\n",
            "Epoch 5 Batch 290 Loss 0.4773\n",
            "Epoch 5 Batch 300 Loss 0.4817\n",
            "Epoch 5 Batch 310 Loss 0.4259\n",
            "Epoch 5 Batch 320 Loss 0.5889\n",
            "Epoch 5 Batch 330 Loss 0.4773\n",
            "Epoch 5 Batch 340 Loss 0.4443\n",
            "Epoch 5 Batch 350 Loss 0.5099\n",
            "Epoch 5 Loss 0.4585\n",
            "Time taken for 1 epoch 30.99650549888611 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3199\n",
            "Epoch 6 Batch 10 Loss 0.2418\n",
            "Epoch 6 Batch 20 Loss 0.2945\n",
            "Epoch 6 Batch 30 Loss 0.3785\n",
            "Epoch 6 Batch 40 Loss 0.2396\n",
            "Epoch 6 Batch 50 Loss 0.3020\n",
            "Epoch 6 Batch 60 Loss 0.3737\n",
            "Epoch 6 Batch 70 Loss 0.2897\n",
            "Epoch 6 Batch 80 Loss 0.2859\n",
            "Epoch 6 Batch 90 Loss 0.3057\n",
            "Epoch 6 Batch 100 Loss 0.3208\n",
            "Epoch 6 Batch 110 Loss 0.2991\n",
            "Epoch 6 Batch 120 Loss 0.3301\n",
            "Epoch 6 Batch 130 Loss 0.2861\n",
            "Epoch 6 Batch 140 Loss 0.3131\n",
            "Epoch 6 Batch 150 Loss 0.2835\n",
            "Epoch 6 Batch 160 Loss 0.2915\n",
            "Epoch 6 Batch 170 Loss 0.2968\n",
            "Epoch 6 Batch 180 Loss 0.3222\n",
            "Epoch 6 Batch 190 Loss 0.2950\n",
            "Epoch 6 Batch 200 Loss 0.2966\n",
            "Epoch 6 Batch 210 Loss 0.3366\n",
            "Epoch 6 Batch 220 Loss 0.3108\n",
            "Epoch 6 Batch 230 Loss 0.2559\n",
            "Epoch 6 Batch 240 Loss 0.3659\n",
            "Epoch 6 Batch 250 Loss 0.3226\n",
            "Epoch 6 Batch 260 Loss 0.3746\n",
            "Epoch 6 Batch 270 Loss 0.3143\n",
            "Epoch 6 Batch 280 Loss 0.2586\n",
            "Epoch 6 Batch 290 Loss 0.3091\n",
            "Epoch 6 Batch 300 Loss 0.3667\n",
            "Epoch 6 Batch 310 Loss 0.2213\n",
            "Epoch 6 Batch 320 Loss 0.2975\n",
            "Epoch 6 Batch 330 Loss 0.3092\n",
            "Epoch 6 Batch 340 Loss 0.3118\n",
            "Epoch 6 Batch 350 Loss 0.3719\n",
            "Epoch 6 Loss 0.3157\n",
            "Time taken for 1 epoch 31.661747932434082 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2285\n",
            "Epoch 7 Batch 10 Loss 0.2575\n",
            "Epoch 7 Batch 20 Loss 0.1831\n",
            "Epoch 7 Batch 30 Loss 0.2291\n",
            "Epoch 7 Batch 40 Loss 0.1165\n",
            "Epoch 7 Batch 50 Loss 0.1546\n",
            "Epoch 7 Batch 60 Loss 0.2011\n",
            "Epoch 7 Batch 70 Loss 0.2334\n",
            "Epoch 7 Batch 80 Loss 0.1817\n",
            "Epoch 7 Batch 90 Loss 0.2328\n",
            "Epoch 7 Batch 100 Loss 0.2318\n",
            "Epoch 7 Batch 110 Loss 0.2162\n",
            "Epoch 7 Batch 120 Loss 0.2495\n",
            "Epoch 7 Batch 130 Loss 0.2506\n",
            "Epoch 7 Batch 140 Loss 0.2211\n",
            "Epoch 7 Batch 150 Loss 0.2368\n",
            "Epoch 7 Batch 160 Loss 0.2452\n",
            "Epoch 7 Batch 170 Loss 0.2820\n",
            "Epoch 7 Batch 180 Loss 0.2232\n",
            "Epoch 7 Batch 190 Loss 0.2452\n",
            "Epoch 7 Batch 200 Loss 0.1906\n",
            "Epoch 7 Batch 210 Loss 0.3487\n",
            "Epoch 7 Batch 220 Loss 0.2409\n",
            "Epoch 7 Batch 230 Loss 0.2472\n",
            "Epoch 7 Batch 240 Loss 0.2073\n",
            "Epoch 7 Batch 250 Loss 0.2212\n",
            "Epoch 7 Batch 260 Loss 0.2279\n",
            "Epoch 7 Batch 270 Loss 0.2785\n",
            "Epoch 7 Batch 280 Loss 0.2399\n",
            "Epoch 7 Batch 290 Loss 0.2130\n",
            "Epoch 7 Batch 300 Loss 0.2170\n",
            "Epoch 7 Batch 310 Loss 0.1972\n",
            "Epoch 7 Batch 320 Loss 0.2445\n",
            "Epoch 7 Batch 330 Loss 0.2652\n",
            "Epoch 7 Batch 340 Loss 0.2298\n",
            "Epoch 7 Batch 350 Loss 0.2126\n",
            "Epoch 7 Loss 0.2233\n",
            "Time taken for 1 epoch 31.313360691070557 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1179\n",
            "Epoch 8 Batch 10 Loss 0.1594\n",
            "Epoch 8 Batch 20 Loss 0.1365\n",
            "Epoch 8 Batch 30 Loss 0.1504\n",
            "Epoch 8 Batch 40 Loss 0.1216\n",
            "Epoch 8 Batch 50 Loss 0.1474\n",
            "Epoch 8 Batch 60 Loss 0.1620\n",
            "Epoch 8 Batch 70 Loss 0.1559\n",
            "Epoch 8 Batch 80 Loss 0.1413\n",
            "Epoch 8 Batch 90 Loss 0.1456\n",
            "Epoch 8 Batch 100 Loss 0.1435\n",
            "Epoch 8 Batch 110 Loss 0.1799\n",
            "Epoch 8 Batch 120 Loss 0.1543\n",
            "Epoch 8 Batch 130 Loss 0.2061\n",
            "Epoch 8 Batch 140 Loss 0.1710\n",
            "Epoch 8 Batch 150 Loss 0.1421\n",
            "Epoch 8 Batch 160 Loss 0.1125\n",
            "Epoch 8 Batch 170 Loss 0.1574\n",
            "Epoch 8 Batch 180 Loss 0.1653\n",
            "Epoch 8 Batch 190 Loss 0.2091\n",
            "Epoch 8 Batch 200 Loss 0.1415\n",
            "Epoch 8 Batch 210 Loss 0.1819\n",
            "Epoch 8 Batch 220 Loss 0.1507\n",
            "Epoch 8 Batch 230 Loss 0.1334\n",
            "Epoch 8 Batch 240 Loss 0.1873\n",
            "Epoch 8 Batch 250 Loss 0.1384\n",
            "Epoch 8 Batch 260 Loss 0.1726\n",
            "Epoch 8 Batch 270 Loss 0.1780\n",
            "Epoch 8 Batch 280 Loss 0.1514\n",
            "Epoch 8 Batch 290 Loss 0.1746\n",
            "Epoch 8 Batch 300 Loss 0.2030\n",
            "Epoch 8 Batch 310 Loss 0.1588\n",
            "Epoch 8 Batch 320 Loss 0.1631\n",
            "Epoch 8 Batch 330 Loss 0.1388\n",
            "Epoch 8 Batch 340 Loss 0.1790\n",
            "Epoch 8 Batch 350 Loss 0.1782\n",
            "Epoch 8 Loss 0.1640\n",
            "Time taken for 1 epoch 31.433653593063354 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1327\n",
            "Epoch 9 Batch 10 Loss 0.1101\n",
            "Epoch 9 Batch 20 Loss 0.1420\n",
            "Epoch 9 Batch 30 Loss 0.0843\n",
            "Epoch 9 Batch 40 Loss 0.1175\n",
            "Epoch 9 Batch 50 Loss 0.1099\n",
            "Epoch 9 Batch 60 Loss 0.1222\n",
            "Epoch 9 Batch 70 Loss 0.1182\n",
            "Epoch 9 Batch 80 Loss 0.1100\n",
            "Epoch 9 Batch 90 Loss 0.0967\n",
            "Epoch 9 Batch 100 Loss 0.1113\n",
            "Epoch 9 Batch 110 Loss 0.1079\n",
            "Epoch 9 Batch 120 Loss 0.1157\n",
            "Epoch 9 Batch 130 Loss 0.1521\n",
            "Epoch 9 Batch 140 Loss 0.1457\n",
            "Epoch 9 Batch 150 Loss 0.1287\n",
            "Epoch 9 Batch 160 Loss 0.1400\n",
            "Epoch 9 Batch 170 Loss 0.1271\n",
            "Epoch 9 Batch 180 Loss 0.1261\n",
            "Epoch 9 Batch 190 Loss 0.1133\n",
            "Epoch 9 Batch 200 Loss 0.1052\n",
            "Epoch 9 Batch 210 Loss 0.1141\n",
            "Epoch 9 Batch 220 Loss 0.1190\n",
            "Epoch 9 Batch 230 Loss 0.1544\n",
            "Epoch 9 Batch 240 Loss 0.1794\n",
            "Epoch 9 Batch 250 Loss 0.1386\n",
            "Epoch 9 Batch 260 Loss 0.1183\n",
            "Epoch 9 Batch 270 Loss 0.0878\n",
            "Epoch 9 Batch 280 Loss 0.1671\n",
            "Epoch 9 Batch 290 Loss 0.1486\n",
            "Epoch 9 Batch 300 Loss 0.1481\n",
            "Epoch 9 Batch 310 Loss 0.0963\n",
            "Epoch 9 Batch 320 Loss 0.1400\n",
            "Epoch 9 Batch 330 Loss 0.1387\n",
            "Epoch 9 Batch 340 Loss 0.1403\n",
            "Epoch 9 Batch 350 Loss 0.1843\n",
            "Epoch 9 Loss 0.1249\n",
            "Time taken for 1 epoch 30.51863431930542 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0796\n",
            "Epoch 10 Batch 10 Loss 0.0807\n",
            "Epoch 10 Batch 20 Loss 0.1032\n",
            "Epoch 10 Batch 30 Loss 0.0703\n",
            "Epoch 10 Batch 40 Loss 0.0951\n",
            "Epoch 10 Batch 50 Loss 0.0798\n",
            "Epoch 10 Batch 60 Loss 0.0906\n",
            "Epoch 10 Batch 70 Loss 0.1238\n",
            "Epoch 10 Batch 80 Loss 0.1099\n",
            "Epoch 10 Batch 90 Loss 0.0863\n",
            "Epoch 10 Batch 100 Loss 0.1028\n",
            "Epoch 10 Batch 110 Loss 0.0889\n",
            "Epoch 10 Batch 120 Loss 0.1006\n",
            "Epoch 10 Batch 130 Loss 0.1088\n",
            "Epoch 10 Batch 140 Loss 0.0878\n",
            "Epoch 10 Batch 150 Loss 0.0918\n",
            "Epoch 10 Batch 160 Loss 0.1025\n",
            "Epoch 10 Batch 170 Loss 0.1279\n",
            "Epoch 10 Batch 180 Loss 0.0871\n",
            "Epoch 10 Batch 190 Loss 0.1011\n",
            "Epoch 10 Batch 200 Loss 0.1377\n",
            "Epoch 10 Batch 210 Loss 0.0838\n",
            "Epoch 10 Batch 220 Loss 0.0931\n",
            "Epoch 10 Batch 230 Loss 0.0954\n",
            "Epoch 10 Batch 240 Loss 0.0864\n",
            "Epoch 10 Batch 250 Loss 0.0819\n",
            "Epoch 10 Batch 260 Loss 0.1213\n",
            "Epoch 10 Batch 270 Loss 0.0983\n",
            "Epoch 10 Batch 280 Loss 0.0840\n",
            "Epoch 10 Batch 290 Loss 0.1128\n",
            "Epoch 10 Batch 300 Loss 0.0934\n",
            "Epoch 10 Batch 310 Loss 0.1250\n",
            "Epoch 10 Batch 320 Loss 0.1304\n",
            "Epoch 10 Batch 330 Loss 0.1156\n",
            "Epoch 10 Batch 340 Loss 0.0647\n",
            "Epoch 10 Batch 350 Loss 0.0855\n",
            "Epoch 10 Loss 0.1013\n",
            "Time taken for 1 epoch 31.03235697746277 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ke6-OHkno25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_len_targ, max_len_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_len_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_len_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdU5L2j9nuwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ojXii78n005",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR114IGgn2pV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "09a53b5a-916a-41e3-92c9-3fbde65078e1"
      },
      "source": [
        "#you can use translate to translate from spanish to english\n",
        "translate(u'hace mucho frio aqui.')\n",
        "\n",
        "#if any trouble you can use this link\n",
        "\"\"\"https://stackoverflow.com/questions/32395880/calculate-bleu-score-in-python\"\"\"\n",
        "# refrence should be actual translated value . you can use many sentences as references to get the bleu scores.\n",
        "reference = ['it','is','too','fast']\n",
        "#hypothesis is the one you got from translating the below graph tell you the predicted translation\n",
        "hypo = [\"it\",\"s\",'too','fast']\n",
        "\n",
        "#run it against reference and hypothesis to find out the bleu score.\n",
        "bleu = nltk.translate.bleu_score.sentence_bleu([reference], hypo)\n",
        "print (bleu)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s too fast . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.7071067811865475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T146NSOvvsV3",
        "colab_type": "text"
      },
      "source": [
        "From this point we will see how to do the same training in parallel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwqMI08pvpwr",
        "colab_type": "code",
        "outputId": "4d2c7960-1f25-4e61-96ba-fc19798ccbca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This part of code allows you to create for virtual gpus on the system if you have only one gpu\n",
        "# you can change memory limit to 2gb if you want to\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if(gpus):\n",
        "    try:\n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "        gpus[0],\n",
        "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),\n",
        "         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print (logical_gpus)\n",
        "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Virtual devices must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Virtual devices cannot be modified after being initialized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1LyuxAMvyjZ",
        "colab_type": "code",
        "outputId": "59d763cb-9cf7-4820-d0da-ea33664dfe43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# this we are setting it for parallel training\n",
        "\n",
        "#intializing mirrored strategy of tensorflow\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "print (strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hul1Iu3DpHHB",
        "colab_type": "text"
      },
      "source": [
        "I have tried to code this thing in parallel and i have done what i could on this thing. Maybe with some assistance i could have done more. But this is code i wrote for parallel training and i have done parallel encoder and attention training. There is some scope issue i am facing which i don't understand becuase i need to go deep into tensorflow repos. i don;t have much time to understand all this. I won;t be submitting any bleu score for parallel model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Fw26-AwUSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    def train_step(inp, targ, enc_hidden):\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        return list((enc_output,dec_hidden,dec_input))\n",
        "\n",
        "    @tf.function\n",
        "    def distributed_train(inp, targ, enc_hidden):\n",
        "        per_replica_losses = strategy.experimental_run_v2(train_step,\n",
        "                                                      args=(inp,targ,enc_hidden,))\n",
        "        \n",
        "        return strategy.experimental_local_results(per_replica_losses)\n",
        "    def loss_function(real, pred):\n",
        "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "        loss_ = loss_object(real, pred)\n",
        "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "        loss_ *= mask\n",
        "        return tf.reduce_mean(loss_)\n",
        "    \n",
        "    num = 5000\n",
        "    input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num)\n",
        "\n",
        "    max_len_targ,max_len_inp = max_length(target_tensor),max_length(input_tensor)\n",
        "\n",
        "    input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.232)\n",
        "    \n",
        "    BUFFER_SIZE = len(input_tensor_train)\n",
        "    BATCH_SIZE = 64\n",
        "    steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "    embedding_dim = 256\n",
        "    units = 1024\n",
        "    vocab_inp_size = len(inp_lang.word_index)+1\n",
        "    vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "    dataset = dataset.batch(BATCH_SIZE*2, drop_remainder=True)\n",
        "    dist_dataset = strategy.experimental_distribute_dataset(dataset)\n",
        "    \n",
        "    encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "    decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    \n",
        "    checkpoint_dir = './training_checkpoints'\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "    checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "    \n",
        "    \n",
        "    EPOCHS = 10\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        start = time.time()\n",
        "        \n",
        "        enc_hidden = encoder.initialize_hidden_state()\n",
        "        \n",
        "        total_loss = 0.0\n",
        "        batch = 0\n",
        "        for (inp, targ) in dist_dataset:\n",
        "            batch = distributed_train(inp, targ, enc_hidden)\n",
        "            targ = targ.values\n",
        "            loss = 0\n",
        "            batch = batch[0]\n",
        "            for i in range(strategy.num_replicas_in_sync):\n",
        "              targ1 = targ[i]\n",
        "              with tf.GradientTape() as tape:\n",
        "                # Teacher forcing - feeding the target as the next input\n",
        "                dec_input = batch[2].values[i]\n",
        "                dec_hidden = batch[1].values[i]\n",
        "                for t in range(1,targ1.shape[1]):\n",
        "                  # passing enc_output to the decoder\n",
        "                  predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, batch[0].values[i])\n",
        "                  loss += loss_function(targ1[:, t], predictions)\n",
        "                  # using teacher forcing\n",
        "                  dec_input = tf.expand_dims(targ1[:, t], 1)\n",
        "\n",
        "                batch_loss = (loss / int(targ1.shape[1]))\n",
        "                variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "                gradients = tape.gradient(loss, variables)\n",
        "                optimizer.apply_gradients(zip(gradients, variables))\n",
        "                loss +=batch_loss\n",
        "            total_loss += loss\n",
        "            batch +=1\n",
        "            \n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "      # saving (checkpoint) the model every 2 epochs\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "            \n",
        "            \n",
        "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}